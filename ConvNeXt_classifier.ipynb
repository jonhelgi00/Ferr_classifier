{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48CkutMutZcr"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "data_dir = '/content/drive/My Drive/Ferritico_assignment'\n",
        "os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "f0H-3pCtxXmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "nY8ny8SdwlxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "\n",
        "class TensorFolderDataset(Dataset):\n",
        "    def __init__(self, root_dir):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (str): Path to the main dataset folder.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.samples = []  # List of (tensor_path, class_idx)\n",
        "\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "\n",
        "        for cls in self.classes:\n",
        "            class_dir = os.path.join(root_dir, cls)\n",
        "            for fname in os.listdir(class_dir):\n",
        "                if fname.endswith(\".pt\"):\n",
        "                    self.samples.append((os.path.join(class_dir, fname), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tensor_path, class_idx = self.samples[idx]\n",
        "        tensor = torch.load(tensor_path)\n",
        "\n",
        "        return tensor, class_idx\n"
      ],
      "metadata": {
        "id": "DJKDVtoxtnqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = os.path.join(data_dir, 'Train')\n",
        "val_data_dir = os.path.join(data_dir, 'Validation')\n",
        "\n",
        "image_datasets = {\n",
        "    'train': TensorFolderDataset(train_data_dir),\n",
        "    'val': TensorFolderDataset(val_data_dir)\n",
        "}\n",
        "\n",
        "# Create dataloaders\n",
        "dataloaders = {\n",
        "    'train': DataLoader(image_datasets['train'], batch_size=32, shuffle=True, num_workers=2),\n",
        "    'val': DataLoader(image_datasets['val'], batch_size=32, shuffle=False, num_workers=2)\n",
        "}\n",
        "\n",
        "# class_names = image_datasets['train'].classes"
      ],
      "metadata": {
        "id": "lFsoA0yRwgp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvNeXt-small, optimizers and scheduler"
      ],
      "metadata": {
        "id": "qE3usr6Yx7Bn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.models import convnext_small, ConvNeXt_Small_Weights\n",
        "\n",
        "def initialize_convnext(num_classes=3, train_last_conv=False):\n",
        "    \"\"\"\n",
        "    Load and modify ConvNeXt-Small for fine-tuning\n",
        "    Args:\n",
        "        train_last_conv: if True, also train the last convolutional block\n",
        "    \"\"\"\n",
        "\n",
        "    model = convnext_small(weights=ConvNeXt_Small_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Freeze all layers by default\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Optionally unfreeze last convolutional block\n",
        "    if train_last_conv:\n",
        "        for param in model.features[-1].parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Flatten(1),\n",
        "        nn.Linear(768, num_classes)\n",
        "    )\n",
        "\n",
        "    for param in model.classifier.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "5rOHigJ4yHc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "# Define loss function, optimizer, and learning rate scheduler\n",
        "def optimizer_setup(model, lr=0.001):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)  # Weight decay for regularization\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
        "\n",
        "  return optimizer, criterion, scheduler"
      ],
      "metadata": {
        "id": "fSZZrQS3zaJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training function"
      ],
      "metadata": {
        "id": "DDP1c3Xqzr9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import copy\n",
        "from torchvision import transforms\n",
        "\n",
        "# # Training function\n",
        "def train_model_convnext(model, criterion, optimizer, scheduler, num_epochs=60, data_augment=False):\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    early_stopping_counter = 0\n",
        "    early_stopping_patience = 20  # Number of epochs with no improvement\n",
        "\n",
        "    #for data augmentation\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.RandomRotation(degrees=15)])\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "\n",
        "                if data_augment and phase == 'train':\n",
        "                  inputs = transform(inputs)\n",
        "\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(image_datasets[phase])\n",
        "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                early_stopping_counter = 0  # Reset counter on improvement\n",
        "                torch.save(model.state_dict(), 'best_model.pt') # Save checkpoint\n",
        "            elif phase == 'val':\n",
        "                early_stopping_counter += 1\n",
        "\n",
        "            if phase == 'val':\n",
        "                scheduler.step(epoch_loss)  # Adjust learning rate based on validation loss\n",
        "\n",
        "            if early_stopping_counter >= early_stopping_patience:\n",
        "                print(\"Early stopping triggered!\")\n",
        "                break\n",
        "\n",
        "        if early_stopping_counter >= early_stopping_patience:\n",
        "            break  #Exit outer loop if early stopping occurs\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, best_acc\n"
      ],
      "metadata": {
        "id": "FYO3z_Wnzwbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Search over parameters"
      ],
      "metadata": {
        "id": "VD_oyP0Y2Jjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import pandas as pd\n",
        "\n",
        "def run_search_experiments():\n",
        "    # Parameters to test\n",
        "    learning_rates = [0.001, 0.0001]\n",
        "    augmentation = [True, False]\n",
        "    conv_training = [True, False]\n",
        "    abs_best_acc = 0\n",
        "    best_params = None\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for lr in learning_rates:\n",
        "        for aug in augmentation:\n",
        "            for train_conv in conv_training:\n",
        "                print(f\"\\nStarting experiment with:\")\n",
        "                print(f\"Learning rate: {lr}\")\n",
        "                print(f\"Augmentation: {aug}\")\n",
        "                print(f\"Training last conv: {train_conv}\")\n",
        "\n",
        "                # Initialize model\n",
        "                model = initialize_convnext(\n",
        "                    num_classes=3,\n",
        "                    train_last_conv=train_conv\n",
        "                )\n",
        "                model = model.to(device)\n",
        "\n",
        "                optimizer, criterion, scheduler = optimizer_setup(model, lr=lr)\n",
        "\n",
        "                # Train model\n",
        "                model, best_acc = train_model_convnext(\n",
        "                    model=model,\n",
        "                    criterion=criterion,\n",
        "                    optimizer=optimizer,\n",
        "                    scheduler=scheduler,\n",
        "                    num_epochs=60,\n",
        "                    data_augment=aug\n",
        "                )\n",
        "\n",
        "                if best_acc > abs_best_acc:\n",
        "                  abs_best_acc = best_acc\n",
        "                  model_save_path = '/content/drive/My Drive/Ferritico_assignment/convnext_best_model.pt'\n",
        "                  torch.save(model.state_dict(), model_save_path)\n",
        "                  best_params = {\n",
        "                      'lr':lr,\n",
        "                      'aug': aug,\n",
        "                      'train_conv': train_conv,\n",
        "                      'best_acc': best_acc\n",
        "                      }\n",
        "\n",
        "                # Store results\n",
        "                results.append({\n",
        "                    'learning_rate': lr,\n",
        "                    'data_augmentation': aug,\n",
        "                    'train_last_conv': train_conv,\n",
        "                    'best_accuracy': best_acc,\n",
        "                })\n",
        "\n",
        "                # Clear GPU memory\n",
        "                del model\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "    # Save and display results\n",
        "    results_df = pd.DataFrame(results)\n",
        "    best_params_df = pd.DataFrame(best_params)\n",
        "\n",
        "    return results_df, best_params_df\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    results_df, best_params_df = run_search_experiments()\n",
        "    print(\"\\nExperiment Results:\")\n",
        "    print(results_df.to_string())\n",
        "\n",
        "    print(\"Best params\")\n",
        "    print(best_params_df.to_string())"
      ],
      "metadata": {
        "id": "62PmD-xd2Odw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = initialize_convnext(num_classes=num_classes, train_last_conv=train_last_conv)\n",
        "model = initialize_convnext()\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/My Drive/Ferritico_assignment/convnext_best_model.pt', map_location=device))\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in dataloaders['val']:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "\n",
        "print(f\"Validation accuracy: {accuracy}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NycmaOchx1bz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}